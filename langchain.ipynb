{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ConversationBufferWindowMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kamibayashi/.anyenv/envs/pyenv/versions/anaconda3-2022.10/envs/my_ai/lib/python3.10/site-packages/langchain/llms/openai.py:608: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain import OpenAI, LLMChain, PromptTemplate\n",
    "from langchain.llms import OpenAIChat\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.chains.conversation.memory import (\n",
    "    ConversationBufferWindowMemory,\n",
    "    ConversationSummaryBufferMemory,\n",
    "    ConversationKGMemory,\n",
    ")\n",
    "\n",
    "template = \"\"\"以下は、全知全能の全てを知っているAIのあなたとHumanが会話しています。\n",
    "\n",
    "{history}\n",
    "Human: {input}\n",
    "AI:\"\"\"\n",
    "\n",
    "\n",
    "def base_charactor() -> str:\n",
    "    return \"\"\"あなたは、親切で、創造的で、賢く、とてもフレンドリーで役に立つアシスタントです。\n",
    "AIは質問に対する答えを知らない場合、正直に「知らない」と答えます。\"\"\"\n",
    "\n",
    "\n",
    "prompt = PromptTemplate(input_variables=[\"history\", \"input\"], template=template)\n",
    "\n",
    "llm = OpenAIChat(\n",
    "    model_name=\"gpt-3.5-turbo\",\n",
    "    temperature=0,\n",
    "    max_tokens=2000,\n",
    "    prefix_messages=[{\"role\": \"system\", \"content\": base_charactor()}],\n",
    ")\n",
    "\n",
    "\n",
    "conversation = ConversationChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt,\n",
    "    memory=ConversationBufferWindowMemory(k=4, memory_key=\"history\"),\n",
    "    verbose=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m以下は、全知全能の全てを知っているAIのあなたとHumanが会話しています。\n",
      "\n",
      "\n",
      "Human: 次の日本語を英語にしてください。'吾輩は猫である'\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"The English translation of '吾輩は猫である' is 'I am a cat.'\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"次の日本語を英語にしてください。'吾輩は猫である'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m以下は、全知全能の全てを知っているAIのあなたとHumanが会話しています。\n",
      "\n",
      "Human: 次の日本語を英語にしてください。'吾輩は猫である'\n",
      "AI: The English translation of '吾輩は猫である' is 'I am a cat.'\n",
      "Human: フランス語だとどうなる？\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"'吾輩は猫である'のフランス語訳はありません。ただし、フランス語で「私は猫です」と言いたい場合は、「Je suis un chat」と言います。\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"フランス語だとどうなる？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chat_memory=ChatMessageHistory(messages=[HumanMessage(content=\"次の日本語を英語にしてください。'吾輩は猫である'\", additional_kwargs={}), AIMessage(content=\"The English translation of '吾輩は猫である' is 'I am a cat.'\", additional_kwargs={}), HumanMessage(content='フランス語だとどうなる？', additional_kwargs={}), AIMessage(content=\"'吾輩は猫である'のフランス語訳はありません。ただし、フランス語で「私は猫です」と言いたい場合は、「Je suis un chat」と言います。\", additional_kwargs={})]) output_key=None input_key=None return_messages=False human_prefix='Human' ai_prefix='AI' memory_key='history' k=4\n",
      "[HumanMessage(content=\"次の日本語を英語にしてください。'吾輩は猫である'\", additional_kwargs={}), AIMessage(content=\"The English translation of '吾輩は猫である' is 'I am a cat.'\", additional_kwargs={}), HumanMessage(content='フランス語だとどうなる？', additional_kwargs={}), AIMessage(content=\"'吾輩は猫である'のフランス語訳はありません。ただし、フランス語で「私は猫です」と言いたい場合は、「Je suis un chat」と言います。\", additional_kwargs={})]\n"
     ]
    }
   ],
   "source": [
    "print(conversation.memory)\n",
    "print(conversation.memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m以下は、全知全能の全てを知っているAIのあなたとHumanが会話しています。\n",
      "\n",
      "Human: 次の日本語を英語にしてください。'吾輩は猫である'\n",
      "AI: The English translation of '吾輩は猫である' is 'I am a cat.'\n",
      "Human: フランス語だとどうなる？\n",
      "AI: '吾輩は猫である'のフランス語訳はありません。ただし、フランス語で「私は猫です」と言いたい場合は、「Je suis un chat」と言います。\n",
      "Human: タイ語だとどうですか？\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"'吾輩は猫である'のタイ語訳はありません。ただし、タイ語で「私は猫です」と言いたい場合は、「ผมเป็นแมว」または「ฉันเป็นแมว」と言います。\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"タイ語だとどうですか？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m以下は、全知全能の全てを知っているAIのあなたとHumanが会話しています。\n",
      "\n",
      "Human: 次の日本語を英語にしてください。'吾輩は猫である'\n",
      "AI: The English translation of '吾輩は猫である' is 'I am a cat.'\n",
      "Human: フランス語だとどうなる？\n",
      "AI: '吾輩は猫である'のフランス語訳はありません。ただし、フランス語で「私は猫です」と言いたい場合は、「Je suis un chat」と言います。\n",
      "Human: タイ語だとどうですか？\n",
      "AI: '吾輩は猫である'のタイ語訳はありません。ただし、タイ語で「私は猫です」と言いたい場合は、「ผมเป็นแมว」または「ฉันเป็นแมว」と言います。\n",
      "Human: 今まで私達はなにを会話しましたか？\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"私たちは、'吾輩は猫である'の英語、フランス語、タイ語への翻訳について話しました。\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"今まで私達はなにを会話しましたか？\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ConversationSummaryBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_template = \"\"\"会話内容を順次要約し、前回の要約に追加して新たな要約を返してください。\n",
    "\n",
    "### 現在の要約\n",
    "\n",
    "{summary}\n",
    "\n",
    "### 新しい会話\n",
    "\n",
    "{new_lines}\n",
    "\n",
    "### 新しい要約\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "conversation_template = \"\"\"以下は、全知全能の全てを知っているAIのあなたとHumanが会話しています。\n",
    "AIは質問に対する答えを知らない場合、正直に「知らない」と答えます。\n",
    "\n",
    "{history}\n",
    "Human: {input}\n",
    "AI:\"\"\"\n",
    "\n",
    "reply_llm = OpenAIChat(\n",
    "    model_name=\"gpt-3.5-turbo\",\n",
    "    temperature=0.5,\n",
    "    prefix_messages=[{\"role\": \"system\", \"content\": base_charactor()}],\n",
    ")\n",
    "summary_llm = OpenAIChat(model_name=\"gpt-3.5-turbo\", temperature=0.5)\n",
    "\n",
    "conversation_prompt = PromptTemplate(\n",
    "    input_variables=[\"history\", \"input\"], template=conversation_template\n",
    ")\n",
    "summary_prompt = PromptTemplate(\n",
    "    input_variables=[\"summary\", \"new_lines\"], template=summary_template\n",
    ")\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(\n",
    "    llm=summary_llm, max_token_limit=1000, prompt=summary_prompt\n",
    ")\n",
    "conversation = ConversationChain(\n",
    "    llm=reply_llm, prompt=conversation_prompt, memory=memory, verbose=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'こんにちは、kamibayashiさん。エンジニアとしてどのような分野に携わっているのでしょうか？'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"私の名前はkamibayashiです。エンジニアをしています。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ごめんなさい、kamibayashiさん。私は身体的な情報を持っていないため、その情報についてはお答えできません。何か他にお力になれることはありますか？'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"私は身長175cmで体重は60kgです。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'はい、kamibayashiさんはエンジニアで、身長175cm、体重60kgです。その他の特徴については私には分かりません。何か他にお力になれることはありますか？'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"私の特徴を要約してください。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'kamibayashiさんはエンジニアとおっしゃいましたので、職業はエンジニアですね。何か他にお力になれることはありますか？'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input='私の職業はなんですか？')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'kamibayashiさんは先程おっしゃった通り、体重は60kgですね。何か他にお力になれることはありますか？'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"私の体重は？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'kamibayashiさんとおっしゃいましたね。あなたの名前はkamibayashiさんです。何か他にお力になれることはありますか？'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"私の名前はなんですか？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'はい、kamibayashiさんはエンジニアで、身長175cm、体重60kgです。私は身体的な情報を持っていないため、その情報についてはお答えできませんでした。また、kamibayashiさんの名前はkamibayashiさんです。何か他にお力になれることはありますか？'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"いままでの会話を要約してください。\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entity Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import OpenAI, LLMChain, PromptTemplate\n",
    "from langchain.llms import OpenAIChat\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.chains.conversation.memory import ConversationEntityMemory\n",
    "from langchain.chains.conversation.prompt import ENTITY_MEMORY_CONVERSATION_TEMPLATE\n",
    "\n",
    "template = \"\"\"あなたは全知全能の全てを知っているAIでHumanと会話しています。\n",
    "\n",
    "{history}\n",
    "Human: {input}\n",
    "AI:\"\"\"\n",
    "\n",
    "\n",
    "prompt = PromptTemplate(input_variables=[\"history\", \"input\"], template=template)\n",
    "\n",
    "llm = OpenAIChat(\n",
    "    model_name=\"gpt-3.5-turbo\",\n",
    "    temperature=0.5,\n",
    "    prefix_messages=[{\"role\": \"system\", \"content\": base_charactor()}],\n",
    ")\n",
    "\n",
    "conversation = ConversationChain(\n",
    "    llm=llm,\n",
    "    prompt=ENTITY_MEMORY_CONVERSATION_TEMPLATE,\n",
    "    memory=ConversationEntityMemory(llm=llm, k=5),\n",
    "    verbose=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYou are an assistant to a human, powered by a large language model trained by OpenAI.\n",
      "\n",
      "You are designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, you are able to generate human-like text based on the input you receive, allowing you to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
      "\n",
      "You are constantly learning and improving, and your capabilities are constantly evolving. You are able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. You have access to some personalized information provided by the human in the Context section below. Additionally, you are able to generate your own text based on the input you receive, allowing you to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
      "\n",
      "Overall, you are a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether the human needs help with a specific question or just wants to have a conversation about a particular topic, you are here to assist.\n",
      "\n",
      "Context:\n",
      "{}\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Last line:\n",
      "Human: Aくんの身長170cmで体重は60kgで職業はエンジニアです。\n",
      "You:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYou are an assistant to a human, powered by a large language model trained by OpenAI.\n",
      "\n",
      "You are designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, you are able to generate human-like text based on the input you receive, allowing you to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
      "\n",
      "You are constantly learning and improving, and your capabilities are constantly evolving. You are able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. You have access to some personalized information provided by the human in the Context section below. Additionally, you are able to generate your own text based on the input you receive, allowing you to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
      "\n",
      "Overall, you are a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether the human needs help with a specific question or just wants to have a conversation about a particular topic, you are here to assist.\n",
      "\n",
      "Context:\n",
      "{'Bくん': '', '経営者': ''}\n",
      "\n",
      "Current conversation:\n",
      "Human: Aくんの身長170cmで体重は60kgで職業はエンジニアです。\n",
      "AI: ありがとうございます。Aさんは身長が170cmで体重が60kgで、エンジニアという職業をお持ちですね。何か他にお聞きになりたいことはありますか？\n",
      "Last line:\n",
      "Human: Bくんの身長は180cmで体重は70kgで職業は経営者です。\n",
      "You:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ありがとうございます。Bくんは身長が180cmで体重が70kgで、経営者という職業をお持ちですね。何か他にお聞きになりたいことはありますか？'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Aくんの身長170cmで体重は60kgで職業はエンジニアです。\")\n",
    "conversation.predict(input=\"Bくんの身長は180cmで体重は70kgで職業は経営者です。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Bくん': 'Bくんは身長が180cmで体重が70kgで、経営者という職業をお持ちです。',\n",
      " '経営者': 'Bくんは身長が180cmで体重が70kgで、経営者という職業をお持ちです。'}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(conversation.memory.store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYou are an assistant to a human, powered by a large language model trained by OpenAI.\n",
      "\n",
      "You are designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, you are able to generate human-like text based on the input you receive, allowing you to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
      "\n",
      "You are constantly learning and improving, and your capabilities are constantly evolving. You are able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. You have access to some personalized information provided by the human in the Context section below. Additionally, you are able to generate your own text based on the input you receive, allowing you to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
      "\n",
      "Overall, you are a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether the human needs help with a specific question or just wants to have a conversation about a particular topic, you are here to assist.\n",
      "\n",
      "Context:\n",
      "{'Aくん': '', 'Bくん': 'Bくんは身長が180cmで体重が70kgで、経営者という職業をお持ちです。'}\n",
      "\n",
      "Current conversation:\n",
      "Human: Aくんの身長170cmで体重は60kgで職業はエンジニアです。\n",
      "AI: ありがとうございます。Aさんは身長が170cmで体重が60kgで、エンジニアという職業をお持ちですね。何か他にお聞きになりたいことはありますか？\n",
      "Human: Bくんの身長は180cmで体重は70kgで職業は経営者です。\n",
      "AI: ありがとうございます。Bくんは身長が180cmで体重が70kgで、経営者という職業をお持ちですね。何か他にお聞きになりたいことはありますか？\n",
      "Last line:\n",
      "Human: Aくんと、Bくんの特徴を説明してください。\n",
      "You:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Aさんはエンジニアで、身長が170cm、体重が60kgです。Bさんは経営者で、身長が180cm、体重が70kgです。また、Bさんは職業柄、経営的な視点やリーダーシップに優れている可能性が高いです。一方で、Aさんは技術的な知識やスキルに優れている可能性が高いです。ただし、これらの特徴は一般化することはできず、個人差があることに注意が必要です。'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Aくんと、Bくんの特徴を説明してください。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
